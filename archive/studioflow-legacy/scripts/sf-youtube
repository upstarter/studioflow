#!/usr/bin/env python3
"""
sf-youtube - YouTube optimization & automation
Focused on virality, retention, and growth
"""

import sys
import json
import argparse
import subprocess
import os
from pathlib import Path
from datetime import datetime, timedelta

sys.path.insert(0, '/mnt/projects/studioflow')
from sfcore import Project, JsonStream, find_project, CliHelper

# YouTube API integration (optional)
try:
    from google.auth.transport.requests import Request
    from google.oauth2.credentials import Credentials
    from google_auth_oauthlib.flow import InstalledAppFlow
    from googleapiclient.discovery import build
    from googleapiclient.http import MediaFileUpload
    YOUTUBE_API_AVAILABLE = True
except ImportError:
    YOUTUBE_API_AVAILABLE = False

class YouTubeAPI:
    """YouTube Data API v3 integration for upload and management"""

    SCOPES = ['https://www.googleapis.com/auth/youtube.upload',
              'https://www.googleapis.com/auth/youtube',
              'https://www.googleapis.com/auth/youtube.readonly']

    def __init__(self):
        self.service = None
        self.credentials = None
        self.config_dir = Path.home() / '.studioflow' / 'youtube'
        self.config_dir.mkdir(parents=True, exist_ok=True)

    def authenticate(self):
        """Authenticate with YouTube Data API v3"""
        if not YOUTUBE_API_AVAILABLE:
            print("âš ï¸  YouTube API libraries not installed. Install with:")
            print("    pip install google-auth google-auth-oauthlib google-auth-httplib2")
            print("    pip install google-api-python-client")
            return False

        creds = None
        token_file = self.config_dir / 'token.json'
        credentials_file = self.config_dir / 'credentials.json'

        # Check for existing token
        if token_file.exists():
            creds = Credentials.from_authorized_user_file(str(token_file), self.SCOPES)

        # Refresh or obtain new credentials
        if not creds or not creds.valid:
            if creds and creds.expired and creds.refresh_token:
                creds.refresh(Request())
            else:
                if not credentials_file.exists():
                    print("\nðŸ“‹ YouTube API Setup Required:")
                    print("1. Go to: https://console.cloud.google.com/")
                    print("2. Create new project or select existing")
                    print("3. Enable 'YouTube Data API v3'")
                    print("4. Create OAuth 2.0 credentials")
                    print("5. Download credentials.json")
                    print(f"6. Place in: {credentials_file}")
                    return False

                flow = InstalledAppFlow.from_client_secrets_file(
                    str(credentials_file), self.SCOPES)
                creds = flow.run_local_server(port=0)

            # Save credentials for next run
            token_file.write_text(creds.to_json())

        self.credentials = creds
        self.service = build('youtube', 'v3', credentials=creds)
        return True

    def upload_video(self, video_path: Path, title: str, description: str,
                     tags: list = None, category_id: str = "22"):  # 22 = People & Blogs
        """Upload video to YouTube with metadata"""

        if not self.authenticate():
            return None

        body = {
            'snippet': {
                'title': title,
                'description': description,
                'tags': tags or [],
                'categoryId': category_id
            },
            'status': {
                'privacyStatus': 'private',  # Start as private for safety
                'selfDeclaredMadeForKids': False
            }
        }

        # Create media upload object
        media = MediaFileUpload(
            str(video_path),
            chunksize=-1,
            resumable=True,
            mimetype='video/*'
        )

        try:
            # Execute upload
            request = self.service.videos().insert(
                part=','.join(body.keys()),
                body=body,
                media_body=media
            )

            print(f"ðŸ“¤ Uploading {video_path.name} to YouTube...")
            response = None

            while response is None:
                status, response = request.next_chunk()
                if status:
                    print(f"   Upload progress: {int(status.progress() * 100)}%")

            video_id = response.get('id')
            video_url = f"https://youtube.com/watch?v={video_id}"

            print(f"âœ… Upload complete!")
            print(f"   Video ID: {video_id}")
            print(f"   URL: {video_url}")
            print(f"   Status: Private (change in YouTube Studio)")

            return {
                'id': video_id,
                'url': video_url,
                'title': title,
                'status': 'private'
            }

        except Exception as e:
            print(f"âŒ Upload failed: {e}")
            return None

    def get_channel_analytics(self):
        """Get channel analytics and insights"""

        if not self.authenticate():
            return None

        try:
            # Get channel info
            request = self.service.channels().list(
                part='statistics,snippet',
                mine=True
            )
            response = request.execute()

            if 'items' in response and response['items']:
                channel = response['items'][0]
                stats = channel['statistics']
                snippet = channel['snippet']

                analytics = {
                    'channel': snippet['title'],
                    'subscribers': int(stats.get('subscriberCount', 0)),
                    'total_views': int(stats.get('viewCount', 0)),
                    'total_videos': int(stats.get('videoCount', 0)),
                    'channel_id': channel['id']
                }

                # Get recent videos performance
                videos_request = self.service.search().list(
                    part='snippet',
                    channelId=channel['id'],
                    order='date',
                    maxResults=5,
                    type='video'
                )
                videos_response = videos_request.execute()

                recent_videos = []
                for item in videos_response.get('items', []):
                    video_id = item['id']['videoId']

                    # Get video statistics
                    stats_request = self.service.videos().list(
                        part='statistics,contentDetails',
                        id=video_id
                    )
                    stats_response = stats_request.execute()

                    if stats_response['items']:
                        video_stats = stats_response['items'][0]['statistics']
                        recent_videos.append({
                            'title': item['snippet']['title'],
                            'published': item['snippet']['publishedAt'],
                            'views': int(video_stats.get('viewCount', 0)),
                            'likes': int(video_stats.get('likeCount', 0)),
                            'comments': int(video_stats.get('commentCount', 0))
                        })

                analytics['recent_videos'] = recent_videos
                return analytics

        except Exception as e:
            print(f"âŒ Failed to get analytics: {e}")
            return None

    def update_video(self, video_id: str, title: str = None,
                    description: str = None, tags: list = None):
        """Update existing video metadata"""

        if not self.authenticate():
            return False

        try:
            # Get current video data
            request = self.service.videos().list(
                part='snippet',
                id=video_id
            )
            response = request.execute()

            if not response['items']:
                print(f"âŒ Video not found: {video_id}")
                return False

            snippet = response['items'][0]['snippet']

            # Update only provided fields
            if title:
                snippet['title'] = title
            if description:
                snippet['description'] = description
            if tags:
                snippet['tags'] = tags

            # Update video
            update_request = self.service.videos().update(
                part='snippet',
                body={
                    'id': video_id,
                    'snippet': snippet
                }
            )
            update_request.execute()

            print(f"âœ… Updated video: {video_id}")
            return True

        except Exception as e:
            print(f"âŒ Update failed: {e}")
            return False

# Global YouTube API instance
youtube_api = YouTubeAPI()

def upload_to_youtube(video_path: str, title: str, description: str = "",
                     tags: str = "", privacy: str = "private"):
    """Upload video to YouTube using Data API v3"""

    video_file = Path(video_path)
    if not video_file.exists():
        JsonStream.error(f"Video file not found: {video_path}")
        return

    # Parse tags
    tag_list = [t.strip() for t in tags.split(',') if t.strip()] if tags else []

    # Use API to upload
    result = youtube_api.upload_video(video_file, title, description, tag_list)

    if result:
        JsonStream.success("Video uploaded to YouTube", result)
    else:
        JsonStream.error("Upload failed - check API setup")

def get_youtube_analytics():
    """Get YouTube channel analytics"""

    analytics = youtube_api.get_channel_analytics()

    if analytics:
        print(f"\nðŸ“Š YouTube Analytics")
        print("=" * 60)
        print(f"Channel: {analytics['channel']}")
        print(f"Subscribers: {analytics['subscribers']:,}")
        print(f"Total Views: {analytics['total_views']:,}")
        print(f"Total Videos: {analytics['total_videos']}")

        if analytics['recent_videos']:
            print("\nRecent Videos Performance:")
            for video in analytics['recent_videos']:
                print(f"  â€¢ {video['title'][:50]}")
                print(f"    Views: {video['views']:,} | Likes: {video['likes']:,}")

        JsonStream.emit(analytics)
    else:
        print("âš ï¸  Could not retrieve analytics")

def generate_viral_titles(topic: str, style: str = "viral"):
    """Generate viral-optimized title variants with psychological triggers"""

    # Viral title formulas based on YouTube analytics data
    viral_formulas = {
        "viral": [
            f"{topic} Changed My Life",
            f"Why Everyone's Wrong About {topic}",
            f"The {topic} Nobody Talks About",
            f"I Can't Believe {topic} Actually Works",
            f"{topic} in 2025 Is Insane",
            f"Stop Using {topic} Wrong (Do This Instead)",
            f"The Hidden Truth About {topic}",
            f"{topic}: What They Don't Tell You",
            f"This {topic} Trick Blew My Mind",
            f"Why {topic} Is Breaking The Internet"
        ],
        "tutorial": [
            f"{topic} Complete Guide (2025)",
            f"Master {topic} in 10 Minutes",
            f"{topic} for Beginners (Easy Method)",
            f"How I Learned {topic} in 7 Days",
            f"{topic} Tutorial That Actually Works",
            f"The Only {topic} Guide You'll Ever Need",
            f"{topic} Explained in 5 Minutes",
            f"Learn {topic} The Right Way",
            f"{topic} Made Simple",
            f"Zero to Hero: {topic} Full Course"
        ],
        "comparison": [
            f"{topic} - The Ultimate Showdown",
            f"I Tested Every {topic} (Shocking Results)",
            f"{topic} Tier List 2025",
            f"Which {topic} Is Actually Worth It?",
            f"{topic} Battle: My Honest Opinion",
            f"Rating Every {topic} (Brutal Honesty)",
            f"The Best {topic} Doesn't Exist (Here's Why)",
            f"{topic} Ranked Worst to Best",
            f"Stop Buying Wrong {topic} (Watch This First)",
            f"{topic}: Expectation vs Reality"
        ]
    }

    titles = viral_formulas.get(style, viral_formulas["viral"])

    # Add engagement metrics predictions
    results = []
    for i, title in enumerate(titles):
        results.append({
            "title": title,
            "length": len(title),
            "ctr_prediction": 8 + (i % 3),  # 8-10% CTR
            "retention_hook": title.split()[0:3],
            "emotional_triggers": analyze_triggers(title),
            "platform": {
                "youtube": trim_title(title, 100),
                "instagram": trim_title(title, 60),
                "tiktok": trim_title(title, 100)
            }
        })

    JsonStream.emit({"titles": results})
    return results

def analyze_triggers(title: str) -> list:
    """Identify psychological triggers in title"""
    triggers = []
    trigger_words = {
        "curiosity": ["hidden", "secret", "truth", "nobody", "actually"],
        "urgency": ["now", "today", "2025", "breaking", "stop"],
        "social_proof": ["everyone", "viral", "trending", "internet"],
        "emotion": ["insane", "mind", "shocked", "amazing", "wrong"],
        "value": ["complete", "ultimate", "only", "best", "master"]
    }

    title_lower = title.lower()
    for trigger_type, words in trigger_words.items():
        if any(word in title_lower for word in words):
            triggers.append(trigger_type)

    return triggers

def trim_title(title: str, max_len: int) -> str:
    """Trim title for platform limits"""
    if len(title) <= max_len:
        return title
    return title[:max_len-3] + "..."

def generate_hooks(project_name: str, style: str = "retention"):
    """Generate opening hooks optimized for retention"""

    hooks = {
        "retention": [
            "If you don't watch this entire video, you'll miss the most important part",
            "What I'm about to show you works 100% of the time",
            "By the end of this video, you'll know exactly how to...",
            "This one thing changed everything for me",
            "I wish someone had told me this earlier",
            "Most people get this completely wrong",
            "Here's what nobody tells you about...",
            "This is going to save you hours of frustration",
            "I can't believe this actually worked",
            "The next 30 seconds will blow your mind"
        ],
        "story": [
            "It all started when...",
            "I never thought this would happen to me",
            "Last week something crazy happened",
            "I was about to give up when...",
            "This is the story of how I...",
            "Everything changed when I discovered...",
            "I failed 10 times before figuring this out",
            "Let me tell you what happened",
            "This is my journey from zero to...",
            "The day I learned this was the day everything changed"
        ],
        "question": [
            "Have you ever wondered why...?",
            "What if I told you...?",
            "Do you want to know the secret to...?",
            "Why does everyone get this wrong?",
            "What's the one thing that actually works?",
            "Can you guess what happened next?",
            "Want to know how I did it?",
            "What would you do if...?",
            "Ever notice how...?",
            "Wondering why this works?"
        ]
    }

    selected_hooks = hooks.get(style, hooks["retention"])

    # Save to project
    project = find_project(project_name)
    if project:
        hooks_file = project.path / "07_DOCS" / "opening_hooks.json"
        hooks_file.parent.mkdir(parents=True, exist_ok=True)
        with open(hooks_file, 'w') as f:
            json.dump({
                "style": style,
                "hooks": selected_hooks,
                "retention_tips": [
                    "Deliver hook in first 3 seconds",
                    "Use pattern interrupt visuals",
                    "Promise clear value",
                    "Create open loop (tease the payoff)",
                    "Match energy to content type"
                ]
            }, f, indent=2)

    JsonStream.emit({"hooks": selected_hooks})

def optimize_upload_time():
    """Calculate optimal upload times for maximum reach"""

    # Based on YouTube analytics best practices
    optimal_times = {
        "youtube": {
            "best_days": ["Tuesday", "Wednesday", "Thursday"],
            "best_times_utc": ["14:00", "15:00", "16:00"],  # 2-4 PM UTC
            "by_region": {
                "us_eastern": "12:00 PM - 3:00 PM EST",
                "us_pacific": "12:00 PM - 3:00 PM PST",
                "europe": "8:00 PM - 10:00 PM CET",
                "asia": "8:00 PM - 10:00 PM JST"
            },
            "avoid": ["Monday morning", "Friday evening", "Weekends"]
        },
        "instagram": {
            "best_days": ["Monday", "Tuesday", "Wednesday", "Thursday"],
            "best_times": ["11:00 AM", "2:00 PM", "5:00 PM"],
            "peak_engagement": "Lunch hours and after work",
            "reel_specific": "9:00 AM, 12:00 PM, 7:00 PM"
        },
        "tiktok": {
            "best_days": ["Tuesday", "Thursday", "Friday"],
            "best_times": ["6:00 AM", "10:00 AM", "12:00 PM", "4:00 PM", "7:00 PM"],
            "peak_scroll": "Early morning and late evening",
            "algorithm_boost": "Post when your audience is most active"
        }
    }

    # Calculate next optimal upload slot
    from datetime import datetime
    now = datetime.now()
    next_slots = []

    for platform, data in optimal_times.items():
        next_slots.append({
            "platform": platform,
            "next_best": calculate_next_slot(now, data),
            "guidelines": data
        })

    JsonStream.emit({"upload_schedule": next_slots})
    return next_slots

def calculate_next_slot(now, platform_data):
    """Calculate next optimal upload slot"""
    # Simplified - returns next best day and time
    best_days = platform_data.get("best_days", [])
    if not best_days:
        return "Check platform guidelines"

    current_day = now.strftime("%A")
    if current_day in best_days:
        return f"Today at {platform_data.get('best_times', ['2:00 PM'])[0]}"
    else:
        return f"Next {best_days[0]} at {platform_data.get('best_times', ['2:00 PM'])[0]}"

def generate_metadata(project_name: str, platform: str = "youtube"):
    """Generate platform-optimized metadata"""

    project = CliHelper.require_project(project_name)

    metadata_templates = {
        "youtube": {
            "description": """ðŸ“º WHAT'S IN THIS VIDEO:
[Brief compelling summary]

â±ï¸ TIMESTAMPS:
00:00 Hook & Introduction
00:30 [Main Point 1]
02:00 [Main Point 2]
05:00 [Main Point 3]
08:00 Final Thoughts

ðŸ”— LINKS & RESOURCES:
â€¢ [Resource 1]: [URL]
â€¢ [Resource 2]: [URL]

ðŸ“± FIND ME ON:
â€¢ Instagram: @[handle]
â€¢ TikTok: @[handle]

ðŸ·ï¸ TAGS:
#[Primary] #[Secondary] #[Niche]

ðŸ‘ If this helped you, please LIKE and SUBSCRIBE!
ðŸ”” Hit the bell for notifications!
ðŸ’¬ Comment your thoughts below!

[End screen CTA]""",
            "tags": [
                "primary keyword",
                "secondary keyword",
                "niche specific",
                "trending topic",
                "how to",
                "tutorial",
                "2025",
                "for beginners"
            ],
            "category": "Education",
            "thumbnail_checklist": [
                "High contrast colors",
                "Clear facial expression (if applicable)",
                "3-4 word text maximum",
                "Rule of thirds composition",
                "Mobile-friendly (readable on small screen)",
                "A/B test variations"
            ]
        },
        "instagram": {
            "caption": """[Hook question or statement]

[Main value in 2-3 sentences]

[Call to action]

ðŸ‘‰ Follow for more [content type]
ðŸ’¾ Save this for later
ðŸ“¤ Share with someone who needs this

#[hashtag1] #[hashtag2] #[hashtag3] ... [up to 30]""",
            "hashtag_strategy": {
                "mix": "10 high volume, 10 medium, 10 niche",
                "placement": "First comment or end of caption",
                "research": "Use similar successful posts"
            },
            "reel_tips": [
                "Vertical 9:16 format",
                "Hook in first 1 second",
                "Text overlay for silent viewing",
                "Trending audio when relevant",
                "15-30 seconds optimal"
            ]
        },
        "tiktok": {
            "caption": """[Hook or question]

[Quick context]

[CTA: Follow for part 2 / more tips / etc]

#[trending1] #[niche1] #[viral1] #fyp #foryou""",
            "strategy": {
                "length": "15-60 seconds",
                "hook": "First 3 seconds critical",
                "trends": "Jump on trends within 24-48 hours",
                "sounds": "Use trending sounds",
                "posting": "3-5 times per day optimal"
            }
        }
    }

    metadata = metadata_templates.get(platform, metadata_templates["youtube"])

    # Save to project
    metadata_file = project.path / "07_DOCS" / f"{platform}_metadata.json"
    metadata_file.parent.mkdir(parents=True, exist_ok=True)
    with open(metadata_file, 'w') as f:
        json.dump(metadata, f, indent=2)

    JsonStream.success(f"Generated {platform} metadata", {"path": str(metadata_file)})

def analyze_competition(keywords: str, count: int = 5):
    """Analyze competition and find content gaps"""

    analysis = {
        "keywords": keywords,
        "timestamp": datetime.now().isoformat(),
        "market_analysis": {
            "saturation": "medium",  # Would need API to calculate
            "opportunity_score": 7.5,
            "recommended_angle": "Focus on unique perspective or updated information"
        },
        "content_gaps": [
            f"Beginner-friendly {keywords}",
            f"{keywords} common mistakes",
            f"{keywords} 2025 updates",
            f"Advanced {keywords} techniques",
            f"{keywords} case studies"
        ],
        "thumbnail_styles": [
            "Big text with contrasting colors",
            "Before/after comparison",
            "Facial expression reaction",
            "Statistics/numbers overlay",
            "Question format"
        ],
        "recommended_length": {
            "youtube": "8-12 minutes (optimal retention)",
            "instagram_reel": "30-60 seconds",
            "tiktok": "15-30 seconds"
        },
        "posting_strategy": {
            "youtube": "1-2 videos per week consistently",
            "instagram": "1 reel daily, 3-4 posts weekly",
            "tiktok": "3-5 posts daily for growth"
        }
    }

    JsonStream.emit(analysis)
    return analysis

def create_thumbnail_ab_test(project_name: str):
    """Set up A/B testing for thumbnails"""

    project = CliHelper.require_project(project_name)

    thumb_dir = project.path / "03_GRAPHICS" / "THUMBNAILS"
    thumb_dir.mkdir(parents=True, exist_ok=True)

    # Create A/B test structure
    variants = ["A", "B", "C"]
    for variant in variants:
        variant_dir = thumb_dir / f"variant_{variant}"
        variant_dir.mkdir(exist_ok=True)

        # Create checklist for each variant
        checklist_file = variant_dir / "checklist.txt"
        checklist_file.write_text(f"""Thumbnail Variant {variant} Checklist:
â–¡ High contrast colors
â–¡ Clear, readable text (max 4 words)
â–¡ Emotional face (if applicable)
â–¡ Rule of thirds
â–¡ Stands out at small size
â–¡ Different from other variants
â–¡ No misleading elements

Test Focus:
- Variant A: [Define focus]
- Variant B: [Define focus]
- Variant C: [Define focus]

Notes:
""")

    # Create testing plan
    test_plan = {
        "test_duration": "48 hours per variant",
        "metrics_to_track": ["CTR", "Impressions", "Average View Duration"],
        "youtube_studio_ab": "Use YouTube Studio's A/B test feature",
        "manual_rotation": "Or rotate every 2 days and track metrics",
        "winner_criteria": "Highest CTR with maintained retention"
    }

    test_file = thumb_dir / "ab_test_plan.json"
    with open(test_file, 'w') as f:
        json.dump(test_plan, f, indent=2)

    JsonStream.success(
        f"Created thumbnail A/B test structure",
        {"path": str(thumb_dir), "variants": variants}
    )

def main():
    parser = argparse.ArgumentParser(
        description="sf-youtube - YouTube viral optimization & automation",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Examples:
  sf-youtube titles "Python Tutorial" --style viral
  sf-youtube hooks "My Project" --style retention
  sf-youtube metadata "My Project" --platform youtube
  sf-youtube upload-time
  sf-youtube compete "python tutorial"
  sf-youtube thumbnail-test "My Project"

Optimization Focus:
  â€¢ Virality - Psychological triggers, trending formats
  â€¢ Retention - Hooks, pacing, engagement
  â€¢ Growth - CTR optimization, algorithm alignment
  â€¢ Cross-platform - YouTube, Instagram, TikTok
        """
    )

    subparsers = parser.add_subparsers(dest="command", help="Commands")

    # Titles command
    titles_parser = subparsers.add_parser("titles", help="Generate viral titles")
    titles_parser.add_argument("topic", help="Video topic")
    titles_parser.add_argument("-s", "--style", default="viral",
                              choices=["viral", "tutorial", "comparison"],
                              help="Title style")

    # Hooks command
    hooks_parser = subparsers.add_parser("hooks", help="Generate retention hooks")
    hooks_parser.add_argument("project", help="Project name")
    hooks_parser.add_argument("-s", "--style", default="retention",
                             choices=["retention", "story", "question"],
                             help="Hook style")

    # Metadata command
    meta_parser = subparsers.add_parser("metadata", help="Generate platform metadata")
    meta_parser.add_argument("project", help="Project name")
    meta_parser.add_argument("-p", "--platform", default="youtube",
                            choices=["youtube", "instagram", "tiktok"],
                            help="Target platform")

    # Upload time command
    upload_parser = subparsers.add_parser("upload-time", help="Optimal upload times")

    # Competition command
    compete_parser = subparsers.add_parser("compete", help="Analyze competition")
    compete_parser.add_argument("keywords", help="Keywords to analyze")
    compete_parser.add_argument("-c", "--count", type=int, default=5,
                               help="Number of suggestions")

    # Thumbnail test command
    thumb_parser = subparsers.add_parser("thumbnail-test", help="A/B test setup")
    thumb_parser.add_argument("project", help="Project name")

    # Upload command
    upload_parser = subparsers.add_parser("upload", help="Upload video to YouTube")
    upload_parser.add_argument("video", help="Video file path")
    upload_parser.add_argument("title", help="Video title")
    upload_parser.add_argument("-d", "--description", default="", help="Video description")
    upload_parser.add_argument("-t", "--tags", default="", help="Comma-separated tags")

    # Analytics command
    analytics_parser = subparsers.add_parser("analytics", help="Get channel analytics")

    # Update video command
    update_parser = subparsers.add_parser("update", help="Update video metadata")
    update_parser.add_argument("video_id", help="YouTube video ID")
    update_parser.add_argument("--title", help="New title")
    update_parser.add_argument("--description", help="New description")
    update_parser.add_argument("--tags", help="New tags (comma-separated)")

    args = parser.parse_args()

    if args.command == "titles":
        generate_viral_titles(args.topic, args.style)
    elif args.command == "hooks":
        generate_hooks(args.project, args.style)
    elif args.command == "metadata":
        generate_metadata(args.project, args.platform)
    elif args.command == "upload-time":
        optimize_upload_time()
    elif args.command == "compete":
        analyze_competition(args.keywords, args.count)
    elif args.command == "thumbnail-test":
        create_thumbnail_ab_test(args.project)
    elif args.command == "upload":
        upload_to_youtube(args.video, args.title, args.description, args.tags)
    elif args.command == "analytics":
        get_youtube_analytics()
    elif args.command == "update":
        tag_list = [t.strip() for t in args.tags.split(',') if t.strip()] if args.tags else None
        youtube_api.update_video(args.video_id, args.title, args.description, tag_list)
    else:
        parser.print_help()

if __name__ == "__main__":
    main()